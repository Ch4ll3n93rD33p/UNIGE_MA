{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP5 - Lea Heiniger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 1 - Monday, November 14, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X.dat', newline='') as f:\n",
    "    reader = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    X_dat = list(reader)\n",
    "with open('Y.dat', newline='') as f:\n",
    "    reader = csv.reader(f, quoting=csv.QUOTE_NONNUMERIC)\n",
    "    Y_dat = list(reader)\n",
    "\n",
    "## 2D array of shape (200, 400), each row (image) contains the 400 grey values of each image\n",
    "X = np.array(X_dat).reshape(200, 400)\n",
    "## list of 200 labels, label for each image, 1 if image is '2' and 0 if image is '3'\n",
    "y_k = [y[0] for y in Y_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE : HELPER FUNCTION, IF NEEDED\n",
    "# Checks if all elements of a list are equal\n",
    "def checkEqual(lst):\n",
    "    '''\n",
    "    checks if all elements of a list are equal\n",
    "    (by checking if the count of the first element is equal to the list length)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lst : list of x elements\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    True if all x elements of the list are equal, and False otherwise\n",
    "    '''\n",
    "    return lst.count(lst[0]) == len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoidal function\n",
    "def fun_sigmoid(x):\n",
    "    # TODO\n",
    "    '''\n",
    "    compute sigmoid of value x\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : scalar value\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    sigmoid(x)\n",
    "    '''\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "# Calculate h-w1-w2\n",
    "def h12(pso, X):\n",
    "    # TODO\n",
    "    '''\n",
    "    calculate state of activation of the output layer of neurons (list of 200 values, a value for each image)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    pso : position vector of one particle\n",
    "    X : 2D array of shape (200, 400), each row (image) contains the 400 grey values of each image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    h : list of 200 values representing the state of activation of the output layer of neurons\n",
    "    '''\n",
    "    # w2 matrix, (1, 26) of last 26 elements of pso\n",
    "    # TODO\n",
    "    w2 = np.array(pso[-26:])\n",
    "\n",
    "    # w1 matrix (25, 401) of first 25*401 elements of pso\n",
    "    # TODO\n",
    "    w1 = []\n",
    "    for i in range(25):\n",
    "        w1.append(pso[401*i:401*i+401])\n",
    "    w1 = np.array(w1)\n",
    "\n",
    "    # results' list containing h value for each image\n",
    "    results = []\n",
    "    # for every image x\n",
    "    for x in X:\n",
    "        # get image (& copy !!)\n",
    "        # TODO\n",
    "        im = x.copy()\n",
    "        \n",
    "        # add 1 at 0-position\n",
    "        # TODO\n",
    "        im = np.insert(im, 0, 1)\n",
    "        \n",
    "        # reshape\n",
    "        # TODO\n",
    "        im = np.reshape(im, (401,1))\n",
    "        \n",
    "        # calculate c = matrix multiplication of weight matrix 1 and image vector(with 1 at position 0)\n",
    "        # TODO\n",
    "        c = np.dot(w1, im)\n",
    "        \n",
    "        # apply sigmoidal function on elements of c\n",
    "        # TODO\n",
    "        z = []\n",
    "        for i in c :\n",
    "            z.append(fun_sigmoid(i))\n",
    "        z = np.array(z)\n",
    "\n",
    "        # add 1 at 0-position\n",
    "        # TODO\n",
    "        z = np.insert(z, 0, 1)\n",
    "        \n",
    "        # reshape\n",
    "        # TODO\n",
    "        z = np.reshape(z, (26,1))\n",
    "        \n",
    "        # calculate matrix multiplication of weight matrix 2 and vector z(with 1 at position 0), answer is scalar\n",
    "        # TODO\n",
    "        r = np.dot(w2, z)\n",
    "        \n",
    "        # apply sigmoidal fucntion on answer\n",
    "        # TODO\n",
    "        h = []\n",
    "        for i in r :\n",
    "            h.append(fun_sigmoid(i))\n",
    "        h = np.array(h)\n",
    "        \n",
    "        # results, append all h12 for all images\n",
    "        # TODO\n",
    "        results.append(h)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Calculate overall fitness J\n",
    "def calculate_J(h, y_k):\n",
    "    # TODO\n",
    "    '''\n",
    "    calculate overall fitness J (equation #5 in TP PDF)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    h : list of 200 values representing the state of activation of the output layer of neurons\n",
    "    y_k : list of 200 labels '1' or '0', for each image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    fitness_J : overall fitness, mean of all J for each image\n",
    "    '''\n",
    "    m = len(y_k)\n",
    "    fitnessSum = 0\n",
    "    \n",
    "    for k in range(m):\n",
    "        fitnessSum += (y_k[k]-h[k])**2\n",
    "        \n",
    "    fitness_J = fitnessSum/m\n",
    "    \n",
    "    return fitness_J\n",
    "        \n",
    "\n",
    "# prediction accuracy of images\n",
    "def pred_acc(h, X, y_k):\n",
    "    # TODO\n",
    "    '''\n",
    "    calculate the prediction accuracy (%) by comparing prediction & true labels\n",
    "    y_p (predicted label) = 1 if h>=0.5 & 0 otherwise\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    h : list of 200 values representing the state of activation of the output layer of neurons (to be used for best h12)\n",
    "    X : 2D array of shape (200, 400), each row (image) contains the 400 grey values of each image\n",
    "    y_k : list of 200 labels '1' or '0', for each image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    acc : prediction accuracy\n",
    "    '''\n",
    "\n",
    "    # get predicted labels\n",
    "    # TODO\n",
    "    y_p = []\n",
    "    for i in range(len(y_k)):\n",
    "        if h[i] >= 0.5 :\n",
    "            y_p.append(1)\n",
    "        else :\n",
    "            y_p.append(0)\n",
    "    \n",
    "    # get prediction accuracy (%)\n",
    "    # TODO\n",
    "    err = 0\n",
    "    for i in range(len(y_k)):\n",
    "        err += (y_p[i]-y_k[i])**2\n",
    "        \n",
    "    err = err / len(y_k)\n",
    "    acc = 1 - err\n",
    "    \n",
    "    return acc*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm, and training the network\n",
    "def pso_NN(X, y_k, N, vmax_coeff):\n",
    "    # TODO\n",
    "    '''\n",
    "    perfom PSO algorithm with NN training\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : 2D array of shape (200, 400), each row (image) contains the 400 grey values of each image\n",
    "    y_k : list of 200 labels '1' or '0', for each image\n",
    "    N : number of particles\n",
    "    vmax_coeff : velocity cutoff coefficient (% of coordinates range, for eg: vmax_coeff=0.1 means vmax=0.1*(xmax_coordinate-xmin_coordinate))\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    J_g : global best fitness\n",
    "    b_g : global best position\n",
    "    h_g : global best state activation of output neurons (needed later for prediction)\n",
    "    J_global : list of all global best positions (for each iteration, needed to plot later on)\n",
    "    '''\n",
    "    J_global = []\n",
    "    ## Fixed Parameters\n",
    "    # cognitive & social parameters\n",
    "    c1 = c2 = 2\n",
    "    # inertia constant\n",
    "    w = 0.9\n",
    "    # number of coefficients 'n' of weight matrices 1 & 2, combined (go back to h12 function for a reminder if needed)\n",
    "    n = 25*401+26\n",
    "    \n",
    "    ## Variate Parameters\n",
    "    # coordinates' range\n",
    "    c_range = [-0.5, 0.5]\n",
    "    \n",
    "    # velocity threshold vmax = vmax_coeff*(c_max - c_min)\n",
    "    # TODO\n",
    "    vmax = vmax_coeff*(c_range[1]-c_range[0])\n",
    "\n",
    "    ## NOTE : STOPPING CONDITION\n",
    "    # choose one of these two stopping conditions: \n",
    "    # 1. number of iterations, tmax=?\n",
    "    # 2. last _ fitness values are equal (or not improving?)\n",
    "    tmax = 100\n",
    "    \n",
    "    ## Initialize\n",
    "    # initialize 's' : np array of size (N=number of particles, n=number of coefficients of weight matrices 1&2) with values from coefficients ranging in c_range\n",
    "    # TODO\n",
    "    s = np.zeros((N,n))\n",
    "    for i in range(N) :\n",
    "        for j in range(n) :\n",
    "            s[i][j] = random.random()-0.5\n",
    "    # initialize 'v' : np array of size(N, n) of velocity vectors of values 0\n",
    "    # TODO\n",
    "    v = np.zeros((N,n))\n",
    "\n",
    "    \n",
    "    ## Compute Initial J\n",
    "    # Compute h12 for all pso in s\n",
    "    # TODO\n",
    "    H = [h12(s[i],X) for i in range(N)]\n",
    "    \n",
    "    # compute and save J for all particles\n",
    "    # TODO\n",
    "    J = [calculate_J(h, y_k) for h in H]\n",
    "    \n",
    "    # get minimum J, and idx (index of minimum)\n",
    "    # TODO\n",
    "    minJ = np.min(J)\n",
    "    index = J.index(minJ)\n",
    "    \n",
    "    # set local & global J (local J is best J for each particle, global J is best overall J)\n",
    "    # TODO\n",
    "    J_g = minJ\n",
    "    J_loc = J.copy()\n",
    "    \n",
    "    # set local & global positions (local position is best b for each particle, global position is best overall b)\n",
    "    # TODO (don't forget to copy if needed !)\n",
    "    b_g = s[index]\n",
    "    b_loc = s.copy()\n",
    "    J_global.append(b_g)\n",
    "    \n",
    "    # save minimum h12 \n",
    "    # TODO\n",
    "    h_g = H[index]\n",
    "    \n",
    "    ## Run algorithm\n",
    "\n",
    "    # STOPPING CONDITION\n",
    "    # TODO\n",
    "    t = 0\n",
    "    while(t<=tmax):\n",
    "\n",
    "        ## For every particle position in s:\n",
    "        for i in range(N) :\n",
    "            # r1, r2 random numbers between 0 & 1\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            # Update v\n",
    "            v[i] = w*v[i]+c1*r1*(b_loc[i]-s[i])+c2*r2*(b_g-s[i])\n",
    "            \n",
    "            \n",
    "            # Check velocity if crossing upper/lower threshold\n",
    "            if np.abs(any(v[i]))> vmax :\n",
    "                for j in range(len(v[i])):\n",
    "                    if v[i][j] > vmax:\n",
    "                        v[i][j] = vmax\n",
    "                    elif v[i][j] < -vmax :\n",
    "                        v[i][j] = -vmax\n",
    "                \n",
    "            \n",
    "            # Update position\n",
    "            s[i] = s[i]+v[i]\n",
    "            \n",
    "            # Check boundary condition & decide what to do if a particle crosses a boundary, some options are:\n",
    "            if np.abs(any(s[i]))> 0.5 :\n",
    "                for j in range(len(s[i])):\n",
    "                    if s[i][j] > 0.5:\n",
    "                        s[i][j] = 0.5\n",
    "                    elif s[i][j] < -0.5 :\n",
    "                        s[i][j] = -0.5  \n",
    "                # set crossing position to the boundary position\n",
    "                # reflect crossing position\n",
    "                # bounce-back crossing position\n",
    "            \n",
    "                \n",
    "            # Calculate new J (by first calculating h12)\n",
    "            h = h12(s[i],X)\n",
    "            J = calculate_J(h, y_k)\n",
    "            \n",
    "            # Check if found new best fitness, set to local fitness\n",
    "            if J < J_loc[i] :\n",
    "                J_loc[i] = J\n",
    "                b_loc[i] = s[i]\n",
    "                \n",
    "        # Get minimum of all new best J, if best is < global J, set to global J\n",
    "        minBestJ = np.min(J_loc)\n",
    "        index = J_loc.index(minBestJ)\n",
    "        \n",
    "        if minBestJ < J_g :\n",
    "            J_g = minBestJ\n",
    "            b_g = b_loc[index]\n",
    "        \n",
    "        \n",
    "        # save best h12\n",
    "        h_g = h12(b_g,X)\n",
    "        \n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return J_g, b_g, h_g, J_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test run pso_NN function for N=10 & vmax_coeff=0.1, and get prediction accuracy\n",
    "# TODO\n",
    "N = 10\n",
    "vmax_coeff = 0.1\n",
    "\n",
    "J_g, b_g, h_g, J_global = pso_NN(X, y_k, N, vmax_coeff)\n",
    "\n",
    "acc = pred_acc(h_g, X, y_k)\n",
    "print(\"we have an accuracy of\",acc,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART 2 - Monday, November 21, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm for range of N, & plot best_fitness vs N (set vmax_coeff=0.1)\n",
    "\n",
    "N = [10, 20, 30, 50]\n",
    "vmax_coeff = 0.1\n",
    "J_g = []\n",
    "\n",
    "for n in N :\n",
    "    J, _, _, _ = pso_NN(X, y_k, n, vmax_coeff)\n",
    "    J_g.append(J)\n",
    "\n",
    "    \n",
    "plt.plot(N, J_g)\n",
    "plt.xlabel('Number of particles')\n",
    "plt.ylabel('Best fitness')\n",
    "plt.title(\"Best fitness found for each number of particles N\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the number of particles affect the result of the PSO algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of particles is the number of solutions that will be generated at each iteration. With more particles we explore more solutions but the computation time required is longer. \n",
    "On the figure above we can see we have a huge improvement in the begining until we reach the best result with 30 particles. After that it starts to worsten slightly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm for range of vmax_coeff, the cutoff velocity coefficient (choose N according to experiment above)\n",
    "vmax_coeff = [0, 0.1, 0.2, 0.3]\n",
    "N = 30\n",
    "\n",
    "for v in vmax_coeff :\n",
    "    J_g, b_g, h_g, J_global = pso_NN(X, y_k, N, v)\n",
    "    print(\"\\n For vmax_coeff =\", v, \"We have a best fitness J =\", J_g) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the velocity cut-off $v_{max}$ affect the result of the PSO algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$v_{max}$ is the cut-off parameter that is used to avoid velocity to reach too large (or too small) values. We can see that with a too small $v_{max}$ the velocity vector is too restrained and the best fitness found is still high. And with a too large $v_{max}$ the velocity values are getting arbitarly high and we once again have a higher fitness.  \n",
    "As we can see above the best fitness is reached with $v_{max}\\_coeff = 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm 10 times, noting the prediction accuracy (or error) for each run \n",
    "# TODO\n",
    "vmax_coeff = 0.2\n",
    "N = 30\n",
    "acc = []\n",
    "J_g = []\n",
    "for i in range(10) :\n",
    "    J, b_g, h_g, J_global = pso_NN(X, y_k, N, vmax_coeff)\n",
    "    acc.append(pred_acc(h_g, X, y_k))\n",
    "    J_g.append(J)\n",
    "    \n",
    "print(\"We ran the algorithm 10 times and got the following accuracies :\\n\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ran 10 times the algorithm with $N = 30$ and $v_{max}\\_coeff = 0.2$ since we hade the best performances with those values previously. We can see that we don't get the same accuracy each time that we run the algorithm. But the worst accuracy that we get is 88.5% (which is still good) and the mean of the accuracies is 93.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best_fitness of each run vs. the number of iterations it took (in case of stop condition #2)\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For one of the 10 runs (choose the one with the best fitness), plot J(w1, w2) as a function of the iteration number\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following Questions: \n",
    "\n",
    "1.  Q: What is the Search Space of our problem?\n",
    "\n",
    "    A: Since the weights are bounded by the interval $[-0.5,0.5]$ and the weight matrix $W_{1}$ and $W_{2}$ are respectively of sizes $25\\times 401$ and $1\\times 26$, the search space is $[-0.5,0.5]^{25\\times 401+1\\times 26}$.\n",
    "\n",
    "\n",
    "2.  Q: Explain the coefficients c1 & c2\n",
    "\n",
    "    A: $c_{1}$ is the coefficient applying on the comportement of a specific particle and $c_{2}$ is the coefficient applying on the comportement of the group of particles. That's why ther are respectively called cognitive coefficient and social coefficient.\n",
    "    \n",
    "\n",
    "3.  Q: How is PSO similar to Ant Algorithm?\n",
    "\n",
    "    A: At each iteration the PSO algorithm generates one solution for each particle. In the same way the Ant algorithm generated one solution for each ant. In both algorithms these solutions are used to create the solutions at next iteration.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
